{
  "hash": "42ac3c74358a86852f84af45309a8ed1",
  "result": {
    "markdown": "---\ntitle: Anomalous ECG Detection\nauthor: Anika Thatavarthy\nimage: ecg.jpg\ndate: '2023-12-06'\ncategories:\n  - code\n---\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWARNING:tensorflow:From C:\\Users\\anika\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n\n```\n:::\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndf = pd.read_csv('./ecg.csv', header=None)\nraw_data = df.values\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>131</th>\n      <th>132</th>\n      <th>133</th>\n      <th>134</th>\n      <th>135</th>\n      <th>136</th>\n      <th>137</th>\n      <th>138</th>\n      <th>139</th>\n      <th>140</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.112522</td>\n      <td>-2.827204</td>\n      <td>-3.773897</td>\n      <td>-4.349751</td>\n      <td>-4.376041</td>\n      <td>-3.474986</td>\n      <td>-2.181408</td>\n      <td>-1.818286</td>\n      <td>-1.250522</td>\n      <td>-0.477492</td>\n      <td>...</td>\n      <td>0.792168</td>\n      <td>0.933541</td>\n      <td>0.796958</td>\n      <td>0.578621</td>\n      <td>0.257740</td>\n      <td>0.228077</td>\n      <td>0.123431</td>\n      <td>0.925286</td>\n      <td>0.193137</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.100878</td>\n      <td>-3.996840</td>\n      <td>-4.285843</td>\n      <td>-4.506579</td>\n      <td>-4.022377</td>\n      <td>-3.234368</td>\n      <td>-1.566126</td>\n      <td>-0.992258</td>\n      <td>-0.754680</td>\n      <td>0.042321</td>\n      <td>...</td>\n      <td>0.538356</td>\n      <td>0.656881</td>\n      <td>0.787490</td>\n      <td>0.724046</td>\n      <td>0.555784</td>\n      <td>0.476333</td>\n      <td>0.773820</td>\n      <td>1.119621</td>\n      <td>-1.436250</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.567088</td>\n      <td>-2.593450</td>\n      <td>-3.874230</td>\n      <td>-4.584095</td>\n      <td>-4.187449</td>\n      <td>-3.151462</td>\n      <td>-1.742940</td>\n      <td>-1.490659</td>\n      <td>-1.183580</td>\n      <td>-0.394229</td>\n      <td>...</td>\n      <td>0.886073</td>\n      <td>0.531452</td>\n      <td>0.311377</td>\n      <td>-0.021919</td>\n      <td>-0.713683</td>\n      <td>-0.532197</td>\n      <td>0.321097</td>\n      <td>0.904227</td>\n      <td>-0.421797</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.490473</td>\n      <td>-1.914407</td>\n      <td>-3.616364</td>\n      <td>-4.318823</td>\n      <td>-4.268016</td>\n      <td>-3.881110</td>\n      <td>-2.993280</td>\n      <td>-1.671131</td>\n      <td>-1.333884</td>\n      <td>-0.965629</td>\n      <td>...</td>\n      <td>0.350816</td>\n      <td>0.499111</td>\n      <td>0.600345</td>\n      <td>0.842069</td>\n      <td>0.952074</td>\n      <td>0.990133</td>\n      <td>1.086798</td>\n      <td>1.403011</td>\n      <td>-0.383564</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.800232</td>\n      <td>-0.874252</td>\n      <td>-2.384761</td>\n      <td>-3.973292</td>\n      <td>-4.338224</td>\n      <td>-3.802422</td>\n      <td>-2.534510</td>\n      <td>-1.783423</td>\n      <td>-1.594450</td>\n      <td>-0.753199</td>\n      <td>...</td>\n      <td>1.148884</td>\n      <td>0.958434</td>\n      <td>1.059025</td>\n      <td>1.371682</td>\n      <td>1.277392</td>\n      <td>0.960304</td>\n      <td>0.971020</td>\n      <td>1.614392</td>\n      <td>1.421456</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 141 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\n\nlabels = raw_data[:, -1]\ndata = raw_data[:, 0:-1]\n\nx_train, x_test, Y_train, Y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n```\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n# scaling the data values\nmin_val = tf.reduce_min(x_train)\nmax_val = tf.reduce_max(x_train)\nx_train = (x_train - min_val) / (max_val - min_val)\nx_test = (x_test - min_val) / (max_val - min_val)\nx_train = tf.cast(x_train, tf.float32)\nx_test = tf.cast(x_test, tf.float32)\n```\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n# formatting the labels\nY_train = Y_train.astype(bool)\nY_test = Y_test.astype(bool)\n\n# segregating the normal and irregular ECG observations\nnormal_x_train = x_train[Y_train]\nirregular_x_train = x_train[~Y_train]\n\nnormal_x_test = x_test[Y_test]\nirregular_x_test = x_test[~Y_test]\n```\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# plotting the normal and irregular ECG observations\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\nax[0].plot(np.arange(140), normal_x_train[-1])\nax[0].set_title('Normal ECG')\nax[0].grid()\nax[1].plot(np.arange(140), irregular_x_train[-1])\nax[1].set_title('Irregular ECG')\nax[1].grid()\n```\n\n::: {.cell-output .cell-output-display}\n![](anomaly_detection_files/figure-html/cell-7-output-1.png){width=1166 height=431}\n:::\n:::\n\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nfrom tensorflow.keras.models import Model\n\nclass Autoencoder(Model):\n  def __init__(self):\n    super(Autoencoder, self).__init__()\n    self.encoder = tf.keras.Sequential([\n      tf.keras.layers.Dense(140, activation='relu'),\n      tf.keras.layers.Dense(32, activation='relu'),\n      tf.keras.layers.Dense(16, activation='relu'),\n      tf.keras.layers.Dense(8, activation='relu'),\n    ])\n    self.decoder = tf.keras.Sequential([\n      tf.keras.layers.Dense(16, activation='relu'),\n      tf.keras.layers.Dense(32, activation='relu'),\n      tf.keras.layers.Dense(140, activation='sigmoid'),\n    ])\n\n  def call(self, x):\n    encoded = self.encoder(x)\n    decoded = self.decoder(encoded)\n    return decoded\n```\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nautoencoder = Autoencoder()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWARNING:tensorflow:From C:\\Users\\anika\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\n```\n:::\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\n# compiling and training the model\nautoencoder.compile(optimizer='adam', loss='mae')\nautoencoder.fit(normal_x_train, normal_x_train, epochs = 20, batch_size=512, validation_data=(normal_x_test, normal_x_test))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWARNING:tensorflow:From C:\\Users\\anika\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\nEpoch 1/20\nWARNING:tensorflow:From C:\\Users\\anika\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n\n\r1/5 [=====>........................] - ETA: 4s - loss: 0.0588\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 1s 47ms/step - loss: 0.0576 - val_loss: 0.0560\nEpoch 2/20\n\r1/5 [=====>........................] - ETA: 0s - loss: 0.0560\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 8ms/step - loss: 0.0548 - val_loss: 0.0525\nEpoch 3/20\n\r1/5 [=====>........................] - ETA: 0s - loss: 0.0525\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 8ms/step - loss: 0.0510 - val_loss: 0.0486\nEpoch 4/20\n\r1/5 [=====>........................] - ETA: 0s - loss: 0.0486\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 8ms/step - loss: 0.0471 - val_loss: 0.0449\nEpoch 5/20\n\r1/5 [=====>........................] - ETA: 0s - loss: 0.0448\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 8ms/step - loss: 0.0435 - val_loss: 0.0415\nEpoch 6/20\n\r1/5 [=====>........................] - ETA: 0s - loss: 0.0414\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 8ms/step - loss: 0.0402 - val_loss: 0.0383\nEpoch 7/20\n\r1/5 [=====>........................] - ETA: 0s - loss: 0.0380\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 5ms/step - loss: 0.0370 - val_loss: 0.0354\nEpoch 8/20\n\r1/5 [=====>........................] - ETA: 0s - loss: 0.0353\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 4ms/step - loss: 0.0343 - val_loss: 0.0331\nEpoch 9/20\n\r1/5 [=====>........................] - ETA: 0s - loss: 0.0333\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 8ms/step - loss: 0.0321 - val_loss: 0.0313\nEpoch 10/20\n\r1/5 [=====>........................] - ETA: 0s - loss: 0.0311\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 8ms/step - loss: 0.0302 - val_loss: 0.0293\nEpoch 11/20\n\r1/5 [=====>........................] - ETA: 0s - loss: 0.0294\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 8ms/step - loss: 0.0284 - val_loss: 0.0277\nEpoch 12/20\n\r1/5 [=====>........................] - ETA: 0s - loss: 0.0276\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 8ms/step - loss: 0.0269 - val_loss: 0.0264\nEpoch 13/20\n\r1/5 [=====>........................] - ETA: 0s - loss: 0.0264\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 8ms/step - loss: 0.0257 - val_loss: 0.0253\nEpoch 14/20\n\r1/5 [=====>........................] - ETA: 0s - loss: 0.0254\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0243\nEpoch 15/20\n\r1/5 [=====>........................] - ETA: 0s - loss: 0.0237\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.0234\nEpoch 16/20\n\r1/5 [=====>........................] - ETA: 0s - loss: 0.0232\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.0226\nEpoch 17/20\n\r1/5 [=====>........................] - ETA: 0s - loss: 0.0223\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0219\nEpoch 18/20\n\r1/5 [=====>........................] - ETA: 0s - loss: 0.0211\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0214\nEpoch 19/20\n\r1/5 [=====>........................] - ETA: 0s - loss: 0.0208\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0208\nEpoch 20/20\n\r1/5 [=====>........................] - ETA: 0s - loss: 0.0210\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0203\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\n<keras.src.callbacks.History at 0x242148dd990>\n```\n:::\n:::\n\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nimport random\ndef plot(data, n, title):\n  enc_img = autoencoder.encoder(data)\n  dec_img = autoencoder.decoder(enc_img)\n  plt.plot(data[n], 'b')\n  plt.title(title)\n  plt.xlabel(\"Time\")\n  plt.ylabel(\"Amplitude\")\n  plt.plot(dec_img[n], 'r')\n  plt.fill_between(np.arange(140), data[n], dec_img[n], color = 'lightcoral')\n  plt.legend(labels=['Input', 'Reconstruction', 'Error'])\n  plt.show()\n\nplot(normal_x_test, random.randint(0, len(normal_x_test)), \"Normal ECG Reconstruction\")\nplot(irregular_x_test, random.randint(0, len(irregular_x_test)), \"Irregular ECG Reconstruction\")\n```\n\n::: {.cell-output .cell-output-display}\n![](anomaly_detection_files/figure-html/cell-11-output-1.png){width=589 height=449}\n:::\n\n::: {.cell-output .cell-output-display}\n![](anomaly_detection_files/figure-html/cell-11-output-2.png){width=597 height=449}\n:::\n:::\n\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\n# calculating the training loss\nreconstructions = autoencoder.predict(normal_x_train)\ntrain_loss = tf.keras.losses.mean_squared_error(reconstructions, normal_x_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\r 1/73 [..............................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r61/73 [========================>.....] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/73 [==============================] - 0s 890us/step\n```\n:::\n:::\n\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nthreshold = np.mean(train_loss) + np.std(train_loss)\n```\n:::\n\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nreconstructed_test = autoencoder.predict(x_test)\n\nlosses = tf.keras.losses.mean_squared_error(reconstructed_test, x_test)\nanomalies = tf.math.less(losses, threshold)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\r 1/32 [..............................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/32 [==============================] - 0s 1ms/step\n```\n:::\n:::\n\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nprint(str.format('Accuracy: {:.2f}', accuracy_score(Y_test, anomalies)))\nprint(str.format('Precision: {:.2f}', precision_score(Y_test, anomalies)))\nprint(str.format('Recall: {:.2f}', recall_score(Y_test, anomalies)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy: 0.94\nPrecision: 0.99\nRecall: 0.91\n```\n:::\n:::\n\n\n",
    "supporting": [
      "anomaly_detection_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}